{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM\n",
    "\n",
    "based on https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text and covert to lowercase\n",
    "filename = \"Bowie_10K.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  293525\n",
      "Total Vocab:  58\n",
      "Total Patterns:  293425\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model with Keras\n",
    "# If you can, try CuDNNLSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement3-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 58)                14906     \n",
      "=================================================================\n",
      "Total params: 279,098\n",
      "Trainable params: 279,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.9000\n",
      "Epoch 00001: loss improved from inf to 2.90000, saving model to weights-improvement3-01-2.9000.hdf5\n",
      "2293/2293 [==============================] - 1110s 484ms/step - loss: 2.9000\n",
      "Epoch 2/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.7400\n",
      "Epoch 00002: loss improved from 2.90000 to 2.74003, saving model to weights-improvement3-02-2.7400.hdf5\n",
      "2293/2293 [==============================] - 1100s 480ms/step - loss: 2.7400\n",
      "Epoch 3/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.6505\n",
      "Epoch 00003: loss improved from 2.74003 to 2.65045, saving model to weights-improvement3-03-2.6505.hdf5\n",
      "2293/2293 [==============================] - 1100s 480ms/step - loss: 2.6505\n",
      "Epoch 4/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.5551\n",
      "Epoch 00004: loss improved from 2.65045 to 2.55513, saving model to weights-improvement3-04-2.5551.hdf5\n",
      "2293/2293 [==============================] - 1103s 481ms/step - loss: 2.5551\n",
      "Epoch 5/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.4503\n",
      "Epoch 00005: loss improved from 2.55513 to 2.45031, saving model to weights-improvement3-05-2.4503.hdf5\n",
      "2293/2293 [==============================] - 1100s 480ms/step - loss: 2.4503\n",
      "Epoch 6/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.3469\n",
      "Epoch 00006: loss improved from 2.45031 to 2.34690, saving model to weights-improvement3-06-2.3469.hdf5\n",
      "2293/2293 [==============================] - 1103s 481ms/step - loss: 2.3469\n",
      "Epoch 7/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.2904\n",
      "Epoch 00007: loss improved from 2.34690 to 2.29042, saving model to weights-improvement3-07-2.2904.hdf5\n",
      "2293/2293 [==============================] - 1112s 485ms/step - loss: 2.2904\n",
      "Epoch 8/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.1974\n",
      "Epoch 00008: loss improved from 2.29042 to 2.19741, saving model to weights-improvement3-08-2.1974.hdf5\n",
      "2293/2293 [==============================] - 1104s 482ms/step - loss: 2.1974\n",
      "Epoch 9/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.1266\n",
      "Epoch 00009: loss improved from 2.19741 to 2.12658, saving model to weights-improvement3-09-2.1266.hdf5\n",
      "2293/2293 [==============================] - 1101s 480ms/step - loss: 2.1266\n",
      "Epoch 10/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.0677\n",
      "Epoch 00010: loss improved from 2.12658 to 2.06766, saving model to weights-improvement3-10-2.0677.hdf5\n",
      "2293/2293 [==============================] - 1110s 484ms/step - loss: 2.0677\n",
      "Epoch 11/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.0128\n",
      "Epoch 00011: loss improved from 2.06766 to 2.01278, saving model to weights-improvement3-11-2.0128.hdf5\n",
      "2293/2293 [==============================] - 1114s 486ms/step - loss: 2.0128\n",
      "Epoch 12/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 1.9704\n",
      "Epoch 00012: loss improved from 2.01278 to 1.97045, saving model to weights-improvement3-12-1.9704.hdf5\n",
      "2293/2293 [==============================] - 1134s 495ms/step - loss: 1.9704\n",
      "Epoch 13/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 1.9305\n",
      "Epoch 00013: loss improved from 1.97045 to 1.93051, saving model to weights-improvement3-13-1.9305.hdf5\n",
      "2293/2293 [==============================] - 1146s 500ms/step - loss: 1.9305\n",
      "Epoch 14/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 1.8885\n",
      "Epoch 00014: loss improved from 1.93051 to 1.88852, saving model to weights-improvement3-14-1.8885.hdf5\n",
      "2293/2293 [==============================] - 1189s 519ms/step - loss: 1.8885\n",
      "Epoch 15/15\n",
      "2293/2293 [==============================] - ETA: 0s - loss: 2.0589\n",
      "Epoch 00015: loss did not improve from 1.88852\n",
      "2293/2293 [==============================] - 1187s 517ms/step - loss: 2.0589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcb5ee53950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=15, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" use it's you that sets the test.\n",
      "so much has gone and little is new\n",
      "and as the sunrise stream\n",
      "flicke \"\n",
      " the soane so the soane she soane sh the soane so meve i want to beeye io the woudg dud yhu wou dan to benee to tee wour  aods cor the soane so toe toane io the soane so the toine io the woudg dud yhu wou dan te ben tee soane io the woudd du s tou late to be late\n",
      "it a mase\n",
      "oo th  love it al tht to meve io a bas\n",
      "aall ih a mast\n",
      "far i lane to be late\n",
      "it a mast\n",
      "oo the fire\n",
      "oo the five\n",
      "oo m man  io soe fove\n",
      "oo mo toe five\n",
      "in a mast\n",
      "and the soane to ben tee soane to ben tee soane io the woudd dud yhu wou dan to benee to tee wour  aods cor the soane so toe toane io the soane so the toine io the woudg dud yhu wou dan te ben tee soane io the woudd du s tou late to be late\n",
      "it a mase\n",
      "oo th  love it al tht to meve io a bas\n",
      "aall ih a mast\n",
      "far i lane to be late\n",
      "it a mast\n",
      "oo the fire\n",
      "oo the five\n",
      "oo m man  io soe fove\n",
      "oo mo toe five\n",
      "in a mast\n",
      "and the soane to ben tee soane to ben tee soane io the woudd dud yhu wou dan to benee to tee wour  aods cor the soane so toe toane io the soane so the toine io t\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" don: 15 million 75 thousand.\n",
      "new york: 80 million.\n",
      "paris: 15 million and 30.\n",
      "china: 1000 million.\n",
      "bi \"\n",
      "d ihse\n",
      "ih mas sh mh the soane so the toane to meve i want to banee tot to the soane so the toine io the woudg dud yhu wou dan te ben tee soane io the woudd du s tou late to be late\n",
      "it a mase\n",
      "oo th  love it al tht to meve io a bas\n",
      "aall ih a mast\n",
      "far i lane to be late\n",
      "it a mast\n",
      "oo the fire\n",
      "oo the five\n",
      "oo m man  io soe fove\n",
      "oo mo toe five\n",
      "in a mast\n",
      "and the soane to ben tee soane to ben tee soane io the woudd dud yhu wou dan to benee to tee wour  aods cor the soane so toe toane io the soane so the toine io the woudg dud yhu wou dan te ben tee soane io the woudd du s tou late to be late\n",
      "it a mase\n",
      "oo th  love it al tht to meve io a bas\n",
      "aall ih a mast\n",
      "far i lane to be late\n",
      "it a mast\n",
      "oo the fire\n",
      "oo the five\n",
      "oo m man  io soe fove\n",
      "oo mo toe five\n",
      "in a mast\n",
      "and the soane to ben tee soane to ben tee soane io the woudd dud yhu wou dan to benee to tee wour  aods cor the soane so toe toane io the soane so the toine io the woudg dud yhu wou dan te ben tee soane io the woudd du s tou late to be late\n",
      "it \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model with Keras\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# load the network weights\n",
    "filename = \"./weights-improvement3-05-2.4481.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
