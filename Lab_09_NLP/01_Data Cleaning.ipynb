{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABBA</th>\n",
       "      <td>[Verse 1] I, I've been in love before I though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David_Bowie</th>\n",
       "      <td>[Intro]  [Verse 1] A small Jean Genie snuck of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Janis_Joplin</th>\n",
       "      <td>[Intro] Oh, come on, come on, come on, come on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael_Jackson</th>\n",
       "      <td>[Verse 1] Your butt is mine, gonna tell you ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queen</th>\n",
       "      <td>[Verse 1] I can dim the lights and sing you so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rolling_Stones</th>\n",
       "      <td>[Intro] What a drag it is getting old  [Verse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Clash</th>\n",
       "      <td>Stay around don't play around This old town an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob_Dylan</th>\n",
       "      <td>[Verse 1] Go away from my window Leave at your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elton_John</th>\n",
       "      <td>[Verse 1] Can you hear it in the distance? Can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Led_Zeppeling</th>\n",
       "      <td>[Intro] Hey That's right  [Verse 1] Asked swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pink_Floyd</th>\n",
       "      <td>[Verse 1] Into the distance, a ribbon of black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ramones</th>\n",
       "      <td>[Intro] 1-2-3-4  [Verse 1] When I'm lying in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Beatles</th>\n",
       "      <td>[Verse 1] Jojo was a man who thought he was a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Doors</th>\n",
       "      <td>Lions in the street and roaming Dogs in heat, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            lyrics\n",
       "ABBA             [Verse 1] I, I've been in love before I though...\n",
       "David_Bowie      [Intro]  [Verse 1] A small Jean Genie snuck of...\n",
       "Janis_Joplin     [Intro] Oh, come on, come on, come on, come on...\n",
       "Michael_Jackson  [Verse 1] Your butt is mine, gonna tell you ri...\n",
       "Queen            [Verse 1] I can dim the lights and sing you so...\n",
       "Rolling_Stones   [Intro] What a drag it is getting old  [Verse ...\n",
       "The_Clash        Stay around don't play around This old town an...\n",
       "Bob_Dylan        [Verse 1] Go away from my window Leave at your...\n",
       "Elton_John       [Verse 1] Can you hear it in the distance? Can...\n",
       "Led_Zeppeling    [Intro] Hey That's right  [Verse 1] Asked swee...\n",
       "Pink_Floyd       [Verse 1] Into the distance, a ribbon of black...\n",
       "Ramones          [Intro] 1-2-3-4  [Verse 1] When I'm lying in m...\n",
       "The_Beatles      [Verse 1] Jojo was a man who thought he was a ...\n",
       "The_Doors        Lions in the street and roaming Dogs in heat, ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv(\"lyrics.csv\",index_col=0)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mausoto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mausoto/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text_1(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special text in brackets ([chorus],[guitar],etc)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)    \n",
    "    # Remove quotes\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    # Remove new line \\n \n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    # Remove stop_word\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(text)\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the updated text\n",
    "data_clean = pd.DataFrame(data_df.lyrics.apply(clean_text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Intro]  [Verse 1] A small Jean Genie snuck off to the city Strung out on lasers and slash back blazers And ate all your razors while pulling the waiters Talking 'bout Monroe and walking on Snow White New York's a go-go and everything tastes nice Poor little Greenie Woo-hoo  (Get back one)  [Chorus] The Jean Genie lives on his back The Jean Genie loves chimney stacks (The Jean Genie) he's outrageous, he screams and he bawls The Jean Genie, let yourself go, oh  [Interlude]  [Verse 2] Sits like a \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.loc['David_Bowie']['lyrics'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' small jean genie snuck city strung lasers slash back blazers ate razors pulling waiters talking bout monroe walking snow white new yorks gogo everything tastes nice poor little greenie woohoo get back one jean genie lives back jean genie loves chimney stacks jean genie hes outrageous screams bawls jean genie let go oh sits like man smiles like reptile loves loves short shell scratch sand wont let go hand says hes beautician sells nutrition keeps dead hair making underwear poor little greenie je'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.loc['David_Bowie']['lyrics'][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of words to be stemmed\n",
    "verb_list = [\"was\",\"were\",\"am\",\"general\",\"generalize\",\"generalizing\",\"insurance\",\"insured\"]\n",
    "noun_list = [\"dogs\",\"feet\",\"insurance\",\"knowledge\"]\n",
    "adjec_list= [\"harder\",\"better\",\"faster\",\"stronger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Porter Stemmer       lancaster Stemmer   \n",
      "was                  wa                   was                 \n",
      "were                 were                 wer                 \n",
      "am                   am                   am                  \n",
      "general              gener                gen                 \n",
      "generalize           gener                gen                 \n",
      "generalizing         gener                gen                 \n",
      "insurance            insur                ins                 \n",
      "insured              insur                ins                 \n",
      "--\n",
      "dogs                 dog                  dog                 \n",
      "feet                 feet                 feet                \n",
      "insurance            insur                ins                 \n",
      "knowledge            knowledg             knowledg            \n",
      "--\n",
      "harder               harder               hard                \n",
      "better               better               bet                 \n",
      "faster               faster               fast                \n",
      "stronger             stronger             stronger            \n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "print(\"%-20s %-20s %-20s\"% (\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
    "for word in verb_list:\n",
    "    print(\"%-20s %-20s %-20s\"%(word, porter.stem(word),lancaster.stem(word)))\n",
    "print(\"--\")\n",
    "for word in noun_list:\n",
    "    print(\"%-20s %-20s %-20s\"%(word, porter.stem(word),lancaster.stem(word)))\n",
    "print(\"--\")\n",
    "for word in adjec_list:\n",
    "    print(\"%-20s %-20s %-20s\"%(word, porter.stem(word),lancaster.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalized\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"generalized\")) # try pos='v':\n",
    "#POS: part of speech ADJ=a, ADJ_SAT=s, ADV=r, NOUN=n, VERB=v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                  WordNet Lemmatizer  \n",
      "was                  be                  \n",
      "were                 be                  \n",
      "am                   be                  \n",
      "general              general             \n",
      "generalize           generalize          \n",
      "generalizing         generalize          \n",
      "insurance            insurance           \n",
      "insured              insure              \n",
      "--\n",
      "dogs                 dog                 \n",
      "feet                 foot                \n",
      "insurance            insurance           \n",
      "knowledge            knowledge           \n",
      "--\n",
      "harder               hard                \n",
      "better               good                \n",
      "faster               fast                \n",
      "stronger             strong              \n"
     ]
    }
   ],
   "source": [
    "print(\"%-20s  %-20s\"% (\"Word\",\"WordNet Lemmatizer\"))\n",
    "for word in verb_list:\n",
    "    print(\"%-20s %-20s\"%(word,lemmatizer.lemmatize(word, pos='v')))\n",
    "print(\"--\")\n",
    "for word in noun_list:\n",
    "    print(\"%-20s %-20s\"%(word,lemmatizer.lemmatize(word, pos='n')))\n",
    "print(\"--\")\n",
    "for word in adjec_list:\n",
    "    print(\"%-20s %-20s\"%(word,lemmatizer.lemmatize(word, pos='a')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mausoto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mausoto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Remember', 'NNP'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('young', 'JJ'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('shone', 'VBP'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sun', 'NN'),\n",
       " ('Shine', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('crazy', 'VBP'),\n",
       " ('diamond', 'NN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagging\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "txt = \"Remember when you were young, you shone like the sun Shine on you crazy diamond\"\n",
    "pos_tag(word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tag list:\n",
    "\n",
    "- CC\tcoordinating conjunction\n",
    "- CD\tcardinal digit\n",
    "- DT\tdeterminer\n",
    "- EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "- FW\tforeign word\n",
    "- IN\tpreposition/subordinating conjunction\n",
    "- JJ\tadjective\t'big'\n",
    "- JJR\tadjective, comparative\t'bigger'\n",
    "- JJS\tadjective, superlative\t'biggest'\n",
    "- LS\tlist marker\t1)\n",
    "- MD\tmodal\tcould, will\n",
    "- NN\tnoun, singular 'desk'\n",
    "- NNS\tnoun plural\t'desks'\n",
    "- NNP\tproper noun, singular\t'Harrison'\n",
    "- NNPS\tproper noun, plural\t'Americans'\n",
    "- PDT\tpredeterminer\t'all the kids'\n",
    "- POS\tpossessive ending\tparent\\'s\n",
    "- PRP\tpersonal pronoun\tI, he, she\n",
    "- PRP\\$ \tpossessive pronoun\tmy, his, hers\n",
    "- RB\tadverb\tvery, silently,\n",
    "- RBR\tadverb, comparative\tbetter\n",
    "- RBS\tadverb, superlative\tbest\n",
    "- RP\tparticle\tgive up\n",
    "- TO\tto\tgo 'to' the store.\n",
    "- UH\tinterjection\terrrrrrrrm\n",
    "- VB\tverb, base form\ttake\n",
    "- VBD\tverb, past tense\ttook\n",
    "- VBG\tverb, gerund/present participle\ttaking\n",
    "- VBN\tverb, past participle\ttaken\n",
    "- VBP\tverb, sing. present, non-3d\ttake\n",
    "- VBZ\tverb, 3rd person sing. present\ttakes\n",
    "- WDT\twh-determiner\twhich\n",
    "- WP\twh-pronoun\twho, what\n",
    "- WP\\$\tpossessive wh-pronoun\twhose\n",
    "- WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tag(text):\n",
    "    lemma=[]\n",
    "    for i,j in pos_tag(word_tokenize(text)) :\n",
    "        p=j[0].lower()\n",
    "        if p in ['j','n','v']:\n",
    "            if p == 'j':\n",
    "                p = 'a'\n",
    "            lemma.append(wnl.lemmatize(i,p))\n",
    "        else :\n",
    "            lemma.append(wnl.lemmatize(i))    \n",
    "    return ' '.join(lemma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small jean genie snuck city strung laser slash back blazer eat razor pull waiter talk bout monroe walk snow white new york gogo everything taste nice poor little greenie woohoo get back one jean genie live back jean genie love chimney stack jean genie he outrageous scream bawl jean genie let go oh sits like man smile like reptile love love short shell scratch sand wont let go hand say he beautician sell nutrition keep dead hair make underwear poor little greenie jean genie live back jean genie l'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.loc['David_Bowie']['lyrics'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(data_clean.lyrics.apply(lemmatize_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small jean genie snuck city strung laser slash back blazer eat razor pull waiter talk bout monroe walk snow white new york gogo everything taste nice poor little greenie woohoo get back one jean genie live back jean genie love chimney stack jean genie he outrageous scream bawl jean genie let go oh sits like man smile like reptile love love short shell scratch sand wont let go hand say he beautician sell nutrition keep dead hair make underwear poor little greenie jean genie live back jean genie l'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.loc['David_Bowie']['lyrics'][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_csv('lyrics_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question\n",
    "1. Which further clean can be aplied to the text?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
