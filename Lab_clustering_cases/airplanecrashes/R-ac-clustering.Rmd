---
title: 'Clustering: Airplane Crashes'
output:
  html_document:
    df_print: paged
---

Load the required libraries
```{r}
library('tm')
library('proxy')
library('ggplot2')
library('wordcloud')
```

Read the data
```{r}
ac_data <- read.csv(file = 'ac_data.csv')
ds<-ac_data
```

Remove the rows with missing Summary details
```{r}
ds = subset(ds, Summary!="")
```

Load text as corpus
```{r}
report <- VCorpus(VectorSource(ds$Summary))
report[[7]]$content
```

Text cleaning:
1) Remove punctuation and numbers
```{r}
report <- tm_map(report,removePunctuation)
report <- tm_map(report,removeNumbers)
report[[7]]$content
```

2) Convert to lowercase
```{r}
report <- tm_map(report,content_transformer(tolower))
report[[7]]$content
```

3) Remove stopwords and strip unnecesary whitespace:
```{r}
report <- tm_map(report, removeWords, stopwords("english"))
report <- tm_map(report, stripWhitespace)
report[[7]]$content
```

Lemmatize (use coreNLP)...and then import texts after lemmatization
```{r}
report_lemma <- read.csv(file = 'report_lemma.csv')
report <- report_lemma
report <- VCorpus(VectorSource(report$Summary))
report_lemma$Summary[[7]]
```

Create the document-terms matrix
```{r}
dtm <- DocumentTermMatrix(report)
dtmmtx <- as.matrix(dtm)
```

Look at the most frequent terms
```{r}
freq <- colSums(as.matrix(dtm)) 
wf <- data.frame(word=names(freq),freq=freq)
```

Remove some of these terms
```{r}
dtm <- DocumentTermMatrix(report,control=list(stopwords=c("aircraft","plane","crash","crashed","caused","accident","one","two","cause","make","kill","result","continue","contribute","take","flight","right","due","lead","factor","minute","leave")))
dtms <- removeSparseTerms(dtm, 0.96)
freq <- colSums(as.matrix(dtms)) 
wf <- data.frame(word=names(freq),freq=freq)
wf_order=wf[order(wf$freq,decreasing = TRUE),]
```

Display the remaining terms according to their frequencies
```{r}
p <- ggplot(subset(wf),aes(word, freq))    
p <- p + geom_bar(stat="identity")   
p <- p + theme(axis.text.x=element_text(angle=90, hjust=1))   
p
```

Display the clouds of words
```{r fig.height=7, fig.width=7}
wordcloud(names(freq),freq,scale=c(5,0.1),colors=brewer.pal(6,"Dark2")) 
```


*********************************
CLUSTERING BY TERMS SIMILARITY
*********************************

Compute the distance matrix
```{r}
dtms[dtms > 1] <- 1
dtms <- as.matrix(dtms)
d <- dist(t(dtms), method = "Jaccard")
```

Build the model via agglomerative clustering
```{r}
hc <- hclust(d,method="ward.D")
```

Visualize clusters by cutting on 12 groups
```{r}
plot(hc,hang=-1)
rect.hclust(hc,k=12,border=2:4)
```


```{r}
A<-findAssocs(dtm,"crew",corlimit=0.1)
A<-unlist(A)
A[1:4]

A<-findAssocs(dtm,"landing",corlimit=0.1)
A<-unlist(A)
A[1:4]


A<-findAssocs(dtm,"weather",corlimit=0.1)
A<-unlist(A)
A[1:4]
```


