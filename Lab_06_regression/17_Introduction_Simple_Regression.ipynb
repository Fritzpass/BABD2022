{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boston Housing Dataset: Load the boston dataset.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating feature and target arrays\n",
    "X, y = boston.data, boston.target\n",
    "columns = boston.feature_names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_boston = pd.DataFrame(X,columns=boston.feature_names)\n",
    "df_boston['target'] = y\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston.to_csv('boston.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(df_boston, x_vars=boston.feature_names, y_vars='target')\n",
    "\n",
    "fig, axes = plt.subplots(3, 5,figsize=[15,8],constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "i=0\n",
    "for x in df_boston.columns[:-1]:\n",
    "    plt.sca(axes[i]) # set the current Axes\n",
    "    plt.scatter(df_boston[x],df_boston.target)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(\"target\")\n",
    "    i+=1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting house value from a single feature\n",
    "X_rooms = df_boston[['RM']]\n",
    "y = df_boston[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot house value as a function of number of rooms using matplotlib's plt dot scatter\n",
    "%matplotlib inline\n",
    "plt.scatter(X_rooms,y)\n",
    "plt.ylabel('Value of house /1000 ($)') #labeling the y label\n",
    "plt.xlabel('Number of rooms') #labeling the x label\n",
    "plt.show()\n",
    "#more rooms lead to higher prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rooms,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #Ordinary Least Squares\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.linear_model import LinearRegression #Ordinary Least Squares\n",
    "import numpy as np\n",
    "\n",
    "regressor = LinearRegression()\n",
    "# fit_intercept : boolean, optional, default True\n",
    "#    whether to calculate the intercept for this model. \n",
    "\n",
    "#normalize : boolean, optional, default False\n",
    "#    This parameter is ignored when fit_intercept is set to False. \n",
    "#    If True, the regressors X will be normalized before regression.\n",
    "\n",
    "#copy_X : boolean, optional, default True\n",
    "#    If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "# Train the model using the training sets\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {} #'normalize':[True,False]\n",
    "\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train, color='blue')\n",
    "plt.scatter(X_test, y_test, color='green')\n",
    "plt.plot(X_test, gs.predict(X_test), color='black',linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated coefficients for the linear regression problem. \n",
    "print('Coefficients: ', gs.best_estimator_.coef_)\n",
    "\n",
    "#Independent term in the linear model.\n",
    "print('Intercept: ', gs.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train=gs.predict(X_train)-y_train\n",
    "error_test=gs.predict(X_test)-y_test\n",
    "\n",
    "error_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gs.predict(X_train),error_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),error_test, c=\"g\", label=\"test data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-1, xmax=50, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_error_train = np.array(error_train).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(error_train)\n",
    "\n",
    "scaled_error_train = scaler.transform(error_train).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(nb_error_train, bins='auto')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot_2samples\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# We test a exponential distribution\n",
    "dist = getattr(scipy.stats, 'norm')\n",
    "param = dist.fit(nb_error_train)\n",
    "    \n",
    "err_mean=param[-2]\n",
    "err_std=param[-1]   \n",
    "\n",
    "# We generate a sample of size  len(mr_scaled) of data distributed according to distribution dist\n",
    "# The function rvs generates a sample with distribution dist with mean loc and std scale\n",
    "test_dist = dist.rvs(*param[0:-2],loc=param[-2], scale=param[-1],size = len(error_train))\n",
    "test_dist.sort()\n",
    "\n",
    "# qq-plot using statsmodels\n",
    "qqplot_2samples(test_dist,np.array(error_train).flatten(),  line='45')\n",
    "plt.show()\n",
    "\n",
    "# We create the percentiles for both distributions\n",
    "percs = np.linspace(0,100,21)\n",
    "q_a = np.percentile(error_train, percs)\n",
    "q_b = np.percentile(test_dist, percs)\n",
    "\n",
    "# and generate the QQ-plot \n",
    "plt.plot(q_a,q_b, ls=\"\", marker=\"o\")\n",
    "plt.title(\"QQ plot\")\n",
    "x = np.linspace(np.min((q_a.min(),q_b.min())), np.max((q_a.max(),q_b.max())))\n",
    "plt.plot(x,x, color=\"k\", ls=\"--\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(error_train,alpha=.3, density=True,bins='auto')\n",
    "plt.hist(test_dist,alpha=.3, density=True,bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolmogorov-Smirnov Test\n",
    "#    Test the distribution G(x) against a given distribution F(x).\n",
    "#    Under the null hypothesis the two distributions are identical, G(x)=F(x).\n",
    "\n",
    "from scipy import stats\n",
    "stats.kstest(scaled_error_train,\"norm\")\n",
    "#stats.kstest(nb_error_train,test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D’Agostino Test\n",
    "#    Under the null hypothesis that the distributions follows a normal distribution.\n",
    "\n",
    "stats.normaltest(scaled_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro test for normality\n",
    "from scipy import stats\n",
    "stats.shapiro(scaled_error_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
