{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Regression Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Boston Housing Dataset: Load the boston dataset.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Creating feature and target arrays\n",
    "X, y = boston.data, boston.target\n",
    "columns = boston.feature_names\n",
    "\n",
    "X=X[y<50]\n",
    "y=y[y<50]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "import numpy as np\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "parameters = {\"n_estimators\":[5,10,100,200], \"criterion\": ['mse'], \n",
    "              \"min_samples_leaf\": [0.03,0.05,0.1,0.3], \"random_state\" : [42]}\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(gs.predict(X_train),gs.predict(X_train)-y_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),gs.predict(X_test)-y_test, c=\"g\", label=\"hold out data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "r = tree.export_text(gs.best_estimator_.estimators_[40],feature_names=columns.tolist(), max_depth=3)\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can export as a figure but we must install graphviz https://graphviz.gitlab.io/download/\n",
    "\n",
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} graphviz\n",
    "#!{sys.executable} -m pip install graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "tree.export_graphviz(gs.best_estimator_.estimators_[0], out_file='tree_from_forest.dot',feature_names=columns.tolist(),max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng tree_from_forest.dot -o tree_from_forest.png -Gdpi=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = 'tree_from_forest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=columns, y=gs.best_estimator_.feature_importances_, palette=\"Blues_d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "base1=SVR(kernel='linear')\n",
    "base2=DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "regressor = AdaBoostRegressor()\n",
    "parameters = {\"n_estimators\":[10,50], \"base_estimator\": [base1,base2], \n",
    "              \"learning_rate\":[0.5,1.0,1.1], \"random_state\" : [4]}\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=gs.predict(X_train)\n",
    "y_pred=gs.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, y_train_pred)) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, y_train_pred)))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test,y_pred)) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(gs.predict(X_train),y_train_pred-y_train, c=\"b\", label=\"training\")\n",
    "plt.scatter(gs.predict(X_test),y_pred-y_test, c=\"g\", label=\"test\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{y_i} = F_M(x_i) = \\sum_{m=1}^{M} h_m(x_i) $$\n",
    "$$ F_m(x) = F_{m-1}(x) + h_m(x)$$\n",
    "$$ h_m =  \\arg\\min_{h} L_m = \\arg\\min_{h} \\sum_{i=1}^{n}\n",
    "l(y_i, F_{m-1}(x_i) + h(x_i))$$\n",
    "\n",
    "$$ F_m(x) = F_{m-1}(x) + \\nu h_m(x)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor = GradientBoostingRegressor() # base_estimator=DecisionTreeRegressor(max_depth=3)\n",
    "parameters = {\"n_estimators\":[20,50,70,100,200], \"learning_rate\":[0.1, 0.5,1,2], \n",
    "              \"random_state\" : [0] ,\n",
    "             \"max_depth\":[1,2]}\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) \n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(gs.predict(X_train),gs.predict(X_train)-y_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),gs.predict(X_test)-y_test, c=\"g\", label=\"hold out data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
