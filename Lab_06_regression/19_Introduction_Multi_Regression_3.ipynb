{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge, Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boston Housing Dataset: Load the boston dataset.\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating feature and target arrays\n",
    "X, y = boston.data, boston.target\n",
    "columns = boston.feature_names\n",
    "\n",
    "X=X[y<50]\n",
    "y=y[y<50]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIDGE REGRESSION\n",
    "\n",
    "The first type of regularized regression that we'll look at is called ridge regression \n",
    "in which our loss function is the standard OLS function plus the squared value of each coefficient \n",
    "multipled by some constant alpha\n",
    "\n",
    "$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2$\n",
    "\n",
    "When minimizing the loss function to fit to our data, models are penalized for\n",
    "coefficients with a large magnitude: large positive and large negative coefficients\n",
    "\n",
    "NOTE that alpha is a parameter that we need to choose in order to fit and predict\n",
    "essentially, we can select the alpha for which our model performs best (hyper parameter tuning)\n",
    "\n",
    "alpha controls model complexity\n",
    "Notice that when alpha=0 we get back OLS (large coeff no penalized - overfitting problem is not accounted for)\n",
    "Very high alpha can lead to underfitting the data (model too simple)\n",
    "alpha controls regularization strength; must be a positive float. \n",
    "\n",
    "Regularization improves the conditioning of the problem and reduces the variance of the estimates. \n",
    "Larger values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "regressor = Ridge()\n",
    "\n",
    "parameters = {\"alpha\": [0.001,0.01,0.1,1,10], \"normalize\": [True, False]}\n",
    "#note that we set alpha using the argument alpha\n",
    "#also notice the argument normalize: setting this equal to True ensures that all \n",
    "#our variables are on the same scale\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#test on hold-out\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Independent term in the linear model.\n",
    "print('Intercept: ', gs.best_estimator_.intercept_)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(list(zip(columns,gs.best_estimator_.coef_)), columns = ['features','estimatedCoefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train=gs.predict(X_train)-y_train\n",
    "error_test=gs.predict(X_test)-y_test\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(gs.predict(X_train),error_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),error_test, c=\"g\", label=\"test data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. \n",
    "\n",
    "$ \\min_{w} ||X w - y||_2 ^ 2 + \\alpha ||w||_1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "regressor = Lasso()\n",
    "parameters = {\"alpha\": [0.001,0.01,0.1,1,10], \"normalize\": [True, False]}\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "lasso_coef = gs.best_estimator_.coef_\n",
    "print(lasso_coef)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#test on hold-out\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train=gs.predict(X_train)-y_train\n",
    "error_test=gs.predict(X_test)-y_test\n",
    "\n",
    "plt.scatter(gs.predict(X_train),error_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),error_test, c=\"g\", label=\"test data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
